{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Davis, T., Love, B. C., & Preston, A. R. (2012). Striatal and hippocampal entropy \n",
    " and recognition signals in category learning: Simultaneous processes revealed by \n",
    " model-based fMRI. Journal of Experimental Psychology. Learning, Memory, and \n",
    " Cognition, 38(4)\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import sea\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% simulation parameters\n",
    "\n",
    "param = {\n",
    "    # how many steps one looksahead? 0 is myopic (1 step ahead) and so on..\n",
    "    'MAX_RECURSION_LEVEL':  5,\n",
    "    'EXPLORATION_PARAM':    0.0,\n",
    "    'DECISION_PARAMETER':   1.0,\n",
    "    'TOTAL_BLOCKS':         30,\n",
    "    'CONSEC_BLOCKS':        2,\n",
    "    'prior_matrix':         np.array([\n",
    "                                [.01, .01],\n",
    "                                [1.0, 1.0],\n",
    "                                [1.0, 1.0],\n",
    "                                [1.0, 1.0],\n",
    "                                [1.0, 1.0]]),\n",
    "    'num_dims':             5,\n",
    "    'num_values':           2,\n",
    "    'coupling':             .3,\n",
    "    'd':                    1.0,\n",
    "    'report':               False,\n",
    "    'NUM_TIMES':            5,\n",
    "}\n",
    "\n",
    "\n",
    "LG_STIM = np.array([\n",
    "    [0, 1, 1, 1, 1],  # exception A (first for later idx)\n",
    "    [1, 0, 1, 1, 1],  # exception B (first for later idx)\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 0],\n",
    "    [1, 1, 0, 0, 1],\n",
    "    [1, 1, 0, 1, 0],\n",
    "    [1, 1, 1, 0, 0],])\n",
    "\n",
    "LG_TRANS_STIM = np.array([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1],\n",
    "    [0, 0, 1, 0, 1],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 0, 0],\n",
    "    [1, 1, 0, 1, 0],\n",
    "    [1, 1, 0, 0, 1],])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % functions for computing utility:\n",
    "\n",
    "def getSituationCost(KNOWN_VEC, param):\n",
    "    '''function to calculate costs for a given KNOWN_VEC (see RMC.SituationValue)\n",
    "\n",
    "    This function assumes equal costs for each query. Can be modified for\n",
    "    tasks in which some tests are more costly than others, or when sampling costs\n",
    "    are not independent.'''\n",
    "\n",
    "    return np.sum(KNOWN_VEC) * 10  # 10 is sampling cost used in paper\n",
    "\n",
    "\n",
    "def dfActionVals(param):\n",
    "    '''function to define utility table (e.g., table 1)\n",
    "\n",
    "    When asym is True, this currently maximizes accuracy (i.e., correct=100\n",
    "    utility units, incorrect=0 utility units).\n",
    "\n",
    "    This function should be modified to reflect utility and cost associated\n",
    "    with the final choice.'''\n",
    "\n",
    "    m = np.diag([100] * param['num_values'])\n",
    "    df = pd.DataFrame(index=['s%d' % a for a in range(param['num_values'])],\n",
    "                      columns=['a%d' % a for a in range(param['num_values'])],\n",
    "                      data=m)\n",
    "    return df\n",
    "\n",
    "\n",
    "param['getSituationCost'] = getSituationCost\n",
    "param['dfActionVals'] = dfActionVals(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating results summary\n",
    "\n",
    "def makeDf(learningSamples,learningAcc,itemRecog,transRecog):\n",
    "    stimTypes = ['exception', 'rule', 'trans']\n",
    "    dvs = ['learningSamples', 'learningAcc', 'itemRecog']\n",
    "    dfRes = pd.DataFrame(index=stimTypes, columns=dvs)\n",
    "    for stimType in stimTypes:\n",
    "        if 'exception' in stimType:\n",
    "            dfRes.loc[stimType, 'learningSamples'] = sum(\n",
    "                learningSamples[0:2]) / (2. * param['TOTAL_BLOCKS'] * param['NUM_TIMES'])\n",
    "            dfRes.loc[stimType, 'learningAcc'] = sum(\n",
    "                learningAcc[0:2]) / (2. * param['TOTAL_BLOCKS'] * param['NUM_TIMES'])\n",
    "            dfRes.loc[stimType, 'itemRecog'] = sum(\n",
    "                itemRecog[0:2]) / (2. * param['NUM_TIMES'])\n",
    "        elif 'rule' in stimType:\n",
    "            dfRes.loc[stimType, 'learningSamples'] = sum(\n",
    "                learningSamples[2:]) / (6. * param['TOTAL_BLOCKS'] * param['NUM_TIMES'])\n",
    "            dfRes.loc[stimType, 'learningAcc'] = sum(\n",
    "                learningAcc[2:]) / (6. * param['TOTAL_BLOCKS'] * param['NUM_TIMES'])\n",
    "            dfRes.loc[stimType, 'itemRecog'] = sum(\n",
    "                itemRecog[2:]) / (6. * param['NUM_TIMES'])\n",
    "        elif 'trans' in stimType:\n",
    "            dfRes.loc[stimType, 'itemRecog'] = sum(\n",
    "                transRecog) / (8. * param['NUM_TIMES'])\n",
    "    return dfRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run: 100%|██████████| 5/5 [03:37<00:00, 44.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickling allSamples to lgSample\n",
      "\n",
      "          learningSamples learningAcc  itemRecog\n",
      "exception         3.13333    0.766983   0.106613\n",
      "rule              2.44556    0.861106  0.0696617\n",
      "trans                 NaN         NaN  0.0720091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% Standard Model Simulation\n",
    "\n",
    "model = sea.RMC(param)\n",
    "\n",
    "LG_KNOWN = np.array([0, 1, 1, 1, 1])\n",
    "LG_QUERY = np.array([1, 0, 0, 0, 0])\n",
    "item_order = np.arange(len(LG_STIM))\n",
    "\n",
    "learningSamples = np.zeros(len(LG_STIM))\n",
    "learningAcc = np.zeros(len(LG_STIM))\n",
    "\n",
    "itemRecog = np.zeros(len(LG_STIM))\n",
    "transRecog = np.zeros(len(LG_TRANS_STIM))\n",
    "clusterPerSim = []\n",
    "\n",
    "allSamples = []\n",
    "\n",
    "\n",
    "for run_num in tqdm(range(param['NUM_TIMES']),desc='run'):\n",
    "\n",
    "    model.Reset()\n",
    "    allSamples.append([])\n",
    "    for num_block in range(\n",
    "            param['TOTAL_BLOCKS']):\n",
    "        np.random.shuffle(item_order)\n",
    "\n",
    "        for item_num in item_order:\n",
    "            tempN = model.PresentStimulus(\n",
    "                LG_STIM[item_num], LG_KNOWN)  # ordered list to sample\n",
    "\n",
    "            allSamples[run_num].append([item_num, tempN])\n",
    "\n",
    "            SAMPLED_KNOWN = np.zeros(model.NUM_DIMS)\n",
    "            SAMPLED_KNOWN[tempN] = 1\n",
    "\n",
    "            correctProb = model.ResponseCorrectProb(\n",
    "                LG_STIM[item_num], SAMPLED_KNOWN)\n",
    "\n",
    "            learningSamples[item_num] += len(tempN)\n",
    "            learningAcc[item_num] += correctProb\n",
    "\n",
    "            model.Learn(LG_STIM[item_num], SAMPLED_KNOWN, LG_QUERY)\n",
    "\n",
    "    clusterPerSim.append(len(model.clusterF) - 1)\n",
    "\n",
    "    # Do Recognition\n",
    "    for item in range(len(LG_STIM)):\n",
    "        model.Stimulate(LG_STIM[item], LG_KNOWN)\n",
    "        itemRecog[item] += sum(model.recog)\n",
    "\n",
    "    for trans_item in range(len(LG_TRANS_STIM)):\n",
    "        model.Stimulate(LG_TRANS_STIM[trans_item], LG_KNOWN)\n",
    "        transRecog[trans_item] += sum(model.recog)\n",
    "\n",
    "\n",
    "print(\"pickling allSamples to lgSample\")\n",
    "pickle.dump(allSamples, open(\"past_samples/rulex_%d_samples\" % param['NUM_TIMES'], \"wb\"))\n",
    "\n",
    "\n",
    "dfRes = makeDf(learningSamples,learningAcc,itemRecog,transRecog)\n",
    "\n",
    "print('')\n",
    "print(dfRes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run: 100%|██████████| 5/5 [00:00<00:00, 17.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          learningSamples learningAcc  itemRecog\n",
      "exception         2.59667    0.569071   0.105942\n",
      "rule              2.62444    0.808033  0.0757691\n",
      "trans                 NaN         NaN  0.0680611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% YOKED Model Simulation\n",
    "model = sea.RMC(param)\n",
    "\n",
    "LG_KNOWN = np.array([0, 1, 1, 1, 1])\n",
    "LG_QUERY = np.array([1, 0, 0, 0, 0])\n",
    "item_order = np.arange(len(LG_STIM))\n",
    "\n",
    "learningSamples = np.zeros(len(LG_STIM))\n",
    "learningAcc = np.zeros(len(LG_STIM))\n",
    "\n",
    "itemRecog = np.zeros(len(LG_STIM))\n",
    "transRecog = np.zeros(len(LG_TRANS_STIM))\n",
    "clusterPerSim = []\n",
    "\n",
    "pastSamples = pickle.load(open(\"past_samples/rulex_%d_samples\" % param['NUM_TIMES'],'rb'))\n",
    "\n",
    "for run_num in tqdm(range(param['NUM_TIMES']),desc='run'):\n",
    "\n",
    "    model.Reset()\n",
    "    trial = 0\n",
    "    for num_block in range(param['TOTAL_BLOCKS']):\n",
    "\n",
    "        np.random.shuffle(item_order)\n",
    "\n",
    "        for item_num in item_order:\n",
    "            tempN = pastSamples[run_num][trial][1]\n",
    "            trial += 1\n",
    "            SAMPLED_KNOWN = np.zeros(model.NUM_DIMS)\n",
    "            SAMPLED_KNOWN[tempN] = 1\n",
    "            model.Stimulate(LG_STIM[item_num], SAMPLED_KNOWN)\n",
    "\n",
    "            correctProb = model.ResponseCorrectProb(\n",
    "                LG_STIM[item_num], SAMPLED_KNOWN)\n",
    "\n",
    "            learningSamples[item_num] += len(tempN)\n",
    "            learningAcc[item_num] += correctProb\n",
    "\n",
    "            model.Learn(LG_STIM[item_num], SAMPLED_KNOWN, LG_QUERY)\n",
    "\n",
    "    # number of observations of each cluster/dimension/value combo + prior.\n",
    "    # first dimension indexes cluster, 2nd the dimension, 3rd the dimension\n",
    "    # value.\n",
    "    clusterPerSim.append(len(model.clusterF) - 1)\n",
    "\n",
    "    # Do Recognition\n",
    "    for item in range(len(LG_STIM)):\n",
    "        model.Stimulate(LG_STIM[item], LG_KNOWN)\n",
    "        itemRecog[item] += sum(model.recog)\n",
    "\n",
    "    for trans_item in range(len(LG_TRANS_STIM)):\n",
    "        model.Stimulate(LG_TRANS_STIM[trans_item], LG_KNOWN)\n",
    "        transRecog[trans_item] += sum(model.recog)\n",
    "\n",
    "\n",
    "dfRes = makeDf(learningSamples,learningAcc,itemRecog,transRecog)\n",
    "\n",
    "print('')\n",
    "print(dfRes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
